{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Example from\n",
    "\n",
    "https://marcotcr.github.io/lime/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html\n",
    "\n",
    "\n",
    "https://github.com/marcotcr/lime/tree/master/doc/notebooks\n",
    "\n",
    "and *Deep Learning with Python*, Chapter 6.\n",
    "\n",
    "Bug solved here: https://github.com/marcotcr/lime/issues/236\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# ensure plots print without needing to call show()\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# import our packages\n",
    "import pandas\n",
    "import numpy\n",
    "import os\n",
    "import gzip\n",
    "import sys\n",
    "import pickle\n",
    "import textwrap\n",
    "\n",
    "import seaborn\n",
    "import wvpy.util\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.pipeline import make_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# set up Keras imports, this can be brittle\n",
    "# no longer import keras, import tensorflow.keras\n",
    "import tensorflow.keras as keras\n",
    "# https://github.com/keras-team/keras/issues/12379#issuecomment-473823330\n",
    "from tensorflow.keras import *\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "from tensorflow.keras.layers import *\n",
    "#from keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D\n",
    "#from keras.models import Model\n",
    "#from keras.optimizers import RMSprop\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop\n",
    "from tensorflow.keras.optimizers import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# get our data and language model through data adaptors\n",
    "sys.path.append('.')\n",
    "# put data load on our path\n",
    "sys.path.append('../data/IMDB')\n",
    "from load_IMDB import load_IMDB\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# load the IMDB data\n",
    "train_data, test_data = load_IMDB()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(\"I would put this at the top of my list of films in the category of unwatchable trash! There are films that are bad, but the worst kind are the ones that are unwatchable but you are suppose to like them because they are supposed to be good for you! The sex sequences, so shocking in its day, couldn't even arouse a rabbit. The so called controversial politics is strictly high school sophomore amateur night Marxism. The film is self-consciously arty in the worst sense of the term. The photography is in a harsh grainy black and white. Some scenes are out of focus or taken from the wrong angle. Even the sound is bad! And some people call this art?<br /><br />\",\n 0)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data.data[5], train_data.target[5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(\"I had high hopes for this one until they changed the name to 'The Shepherd : Border Patrol, the lamest movie name ever, what was wrong with just 'The Shepherd'. This is a by the numbers action flick that tips its hat at many classic Van Damme films. There is a nice bit of action in a bar which reminded me of hard target and universal soldier but directed with no intensity or flair which is a shame. There is one great line about 'being p*ss drunk and carrying a rabbit' and some OK action scenes let down by the cheapness of it all. A lot of the times the dialogue doesn't match the characters mouth and the stunt men fall down dead a split second before even being shot. The end fight is one of the better Van Damme fights except the Director tries to go a bit too John Woo and fails also introducing flashbacks which no one really cares about just gets in the way of the action which is the whole point of a van Damme film.<br /><br />Not good, not bad, just average generic action.\",\n 0)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_data.data[5], test_data.target[5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training a classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's tokenize the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "max_len = 300\n",
    "embed_dim = 24\n",
    "\n",
    "tok = keras.preprocessing.text.Tokenizer(num_words=vocab_size)\n",
    "# all fitting, including tokenizers is done only on training data\n",
    "tok.fit_on_texts(train_data.data)\n",
    "\n",
    "# shuffle rows of training data in case neural net batching takes in ordered chunks\n",
    "permutation = numpy.random.choice(len(train_data.data), size=len(train_data.data), replace=False)\n",
    "train_data_shuffled = [train_data.data[i] for i in permutation]\n",
    "train_target_shuffled = [train_data.target[i] for i in permutation]\n",
    "\n",
    "# convert training data\n",
    "train_text = tok.texts_to_sequences(train_data_shuffled)\n",
    "train_text = keras.preprocessing.sequence.pad_sequences(\n",
    "    train_text, maxlen=max_len,\n",
    "    padding=\"post\", truncating=\"post\")\n",
    "train_target = numpy.asarray(train_target_shuffled, dtype=float)\n",
    "\n",
    "# convert test data\n",
    "test_text = tok.texts_to_sequences(test_data.data)\n",
    "test_text = keras.preprocessing.sequence.pad_sequences(\n",
    "    test_text, maxlen=max_len,\n",
    "    padding=\"post\", truncating=\"post\")\n",
    "test_target = numpy.asarray(test_data.target, dtype=float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now define our neural net.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define our neural net\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embed_dim, input_length = max_len))\n",
    "model.add(Bidirectional(LSTM(64)))  # or model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the initial state of the model, this lets us re-train. Having to pick the epoch and re-trian in this way is a bit non-standard and is evidence we are running this example on too little data and/or haven't taken enough precautions against over-fit (such as drop-out layers). Usually more epochs is better."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wts = model.get_weights()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(train_text, train_target, epochs=20,\n",
    "                    batch_size=256, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_trajectory = pandas.DataFrame(history.history)\n",
    "training_trajectory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seaborn.lineplot(data = training_trajectory[['loss', 'val_loss']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_epoch_id = training_trajectory.val_loss.idxmin()\n",
    "best_epoch_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The early divergence of the train and validation curves is a bad sign.\n",
    "\n",
    "For this data set a small epochs is pretty good (using validation loss as the criterion).\n",
    "\n",
    "This is a stong sign of not having enough data for the task of learning the language model/embedding.\n",
    "\n",
    "We will re-run to an early stage and look at our results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.set_weights(wts)\n",
    "model.fit(train_text, train_target, epochs=best_epoch_id + 1,\n",
    "                    batch_size=32, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tensorflow now implements .predict_proba() as .predict()\n",
    "preds_train = pandas.DataFrame(model.predict(train_text))\n",
    "preds_train.columns = [\"prediction\"]\n",
    "preds_train[\"actual\"] = train_target\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds_test = pandas.DataFrame(model.predict(test_text))\n",
    "preds_test.columns = [\"prediction\"]\n",
    "preds_test[\"actual\"] = test_target\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wvpy.util.plot_roc(\n",
    "    preds_train[\"prediction\"],\n",
    "    preds_train[\"actual\"],\n",
    "    title='training performance')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wvpy.util.threshold_plot(\n",
    "    preds_train,\n",
    "    pred_var=\"prediction\",\n",
    "    truth_var=\"actual\",\n",
    "    plotvars=('precision', 'recall', 'accuracy'),\n",
    "    title='training performance',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# estimate accuracy on train\n",
    "numpy.mean((preds_train.actual >= 0.5) == (preds_train.prediction >= 0.5))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wvpy.util.plot_roc(\n",
    "    preds_test[\"prediction\"],\n",
    "    preds_test[\"actual\"],\n",
    "    title='test performance')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wvpy.util.threshold_plot(\n",
    "    preds_test,\n",
    "    pred_var=\"prediction\",\n",
    "    truth_var=\"actual\",\n",
    "    plotvars=('precision', 'recall', 'accuracy'),\n",
    "    title='test performance',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# estimate accuracy on test\n",
    "numpy.mean((preds_test.actual >= 0.5) == (preds_test.prediction >= 0.5))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# accuracy at another threshold\n",
    "numpy.mean((preds_test.actual >= 0.3) == (preds_test.prediction >= 0.3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}